# -*- coding: utf-8 -*-
"""urinary_cancer_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u6PYdHzbDE2E5YOnZDbpbgXm7iN2m3gm
"""

!pip install lime

!pip install gdown

import pandas as pd
import numpy as np

from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder

from sklearn.linear_model import LogisticRegression, ElasticNet
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
import lightgbm as lgb
from lightgbm import LGBMClassifier
from sklearn.naive_bayes import GaussianNB

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, LSTM

from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV

from sklearn.cluster import KMeans

import shap
import lime
import lime.lime_tabular

import gdown

# load the dataset
df = pd.read_csv('/content/SEER_URINARY.csv')

# Corrected Google Drive download link
#url = 'https://drive.google.com/uc?id=1K6kxPaS4BvuExw1fzl95tfJWa4O2Ch9g'

# Download the file
#gdown.download(url, 'urinary.csv', quiet=False)

# Load the CSV into a DataFrame
#df = pd.read_csv('urinary.csv')

# Display the first few rows
df.head()

df.shape

df.describe()

# 1. Drop `Unnamed` or unnecessary columns (assuming 'Unnamed' column is an index or unnecessary column)
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

# Calculate percentage of missing values for each column
missing_percentage = df.isnull().mean() * 100

# Keep only columns with less than 10% missing values
columns_to_keep = missing_percentage[missing_percentage < 20].index
df = df[columns_to_keep]

from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
import pandas as pd

# Separate categorical and numerical columns
categorical_columns = df.select_dtypes(include=['object']).columns
numerical_columns = df.select_dtypes(exclude=['object']).columns

# Apply LabelEncoder to categorical columns for RandomForestClassifier training
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))  # Converting categories to numerical values for classification
    label_encoders[col] = le

# Impute missing values in categorical columns using RandomForestClassifier
for col in categorical_columns:
    # If there are missing values in the column
    if df[col].isnull().any():
        # Separate the rows with and without missing values in the current column
        df_no_missing = df[df[col].notnull()]
        df_missing = df[df[col].isnull()]

        # Prepare the features (other columns) for training the model
        X_train = df_no_missing.drop(columns=[col])  # All columns except the one to be imputed
        y_train = df_no_missing[col]  # The column to be imputed

        X_test = df_missing.drop(columns=[col])  # Features for rows with missing values

        # Train a RandomForestClassifier to predict the missing categorical values
        rf_classifier = RandomForestClassifier(random_state=42)
        rf_classifier.fit(X_train, y_train)

        # Predict the missing values and fill them in the DataFrame
        df.loc[df_missing.index, col] = rf_classifier.predict(X_test)

# Impute missing values in numerical columns using RandomForestRegressor
for col in numerical_columns:
    # If there are missing values in the column
    if df[col].isnull().any():
        # Separate the rows with and without missing values in the current column
        df_no_missing = df[df[col].notnull()]
        df_missing = df[df[col].isnull()]

        # Prepare the features (other columns) for training the model
        X_train = df_no_missing.drop(columns=[col])  # All columns except the one to be imputed
        y_train = df_no_missing[col]  # The column to be imputed

        X_test = df_missing.drop(columns=[col])  # Features for rows with missing values

        # Train a RandomForestRegressor to predict the missing numerical values
        rf_regressor = RandomForestRegressor(random_state=42)
        rf_regressor.fit(X_train, y_train)

        # Predict the missing values and fill them in the DataFrame
        df.loc[df_missing.index, col] = rf_regressor.predict(X_test)

# Reverse the encoding to get original categorical values back
for col in categorical_columns:
    df[col] = label_encoders[col].inverse_transform(df[col].astype(int))

# Now, df has both numerical columns imputed with RandomForestRegressor and categorical columns imputed with RandomForestClassifier

df.shape

from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
import pandas as pd

# Separate categorical and numerical columns
categorical_columns = df.select_dtypes(include=['object']).columns
numerical_columns = df.select_dtypes(exclude=['object']).columns

# Apply LabelEncoder to categorical columns for RandomForestClassifier training
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))  # Converting categories to numerical values for classification
    label_encoders[col] = le

# Impute missing values in categorical columns using RandomForestClassifier
for col in categorical_columns:
    # If there are missing values in the column
    if df[col].isnull().any():
        # Separate the rows with and without missing values in the current column
        df_no_missing = df[df[col].notnull()]
        df_missing = df[df[col].isnull()]

        # Prepare the features (other columns) for training the model
        X_train = df_no_missing.drop(columns=[col])  # All columns except the one to be imputed
        y_train = df_no_missing[col]  # The column to be imputed

        X_test = df_missing.drop(columns=[col])  # Features for rows with missing values

        # Train a RandomForestClassifier to predict the missing categorical values
        rf_classifier = RandomForestClassifier(random_state=42)
        rf_classifier.fit(X_train, y_train)

        # Predict the missing values and fill them in the DataFrame
        df.loc[df_missing.index, col] = rf_classifier.predict(X_test)

# Impute missing values in numerical columns using RandomForestRegressor
for col in numerical_columns:
    # If there are missing values in the column
    if df[col].isnull().any():
        # Separate the rows with and without missing values in the current column
        df_no_missing = df[df[col].notnull()]
        df_missing = df[df[col].isnull()]

        # Prepare the features (other columns) for training the model
        X_train = df_no_missing.drop(columns=[col])  # All columns except the one to be imputed
        y_train = df_no_missing[col]  # The column to be imputed

        X_test = df_missing.drop(columns=[col])  # Features for rows with missing values

        # Train a RandomForestRegressor to predict the missing numerical values
        rf_regressor = RandomForestRegressor(random_state=42)
        rf_regressor.fit(X_train, y_train)

        # Predict the missing values and fill them in the DataFrame
        df.loc[df_missing.index, col] = rf_regressor.predict(X_test)

# Reverse the encoding to get original categorical values back
for col in categorical_columns:
    df[col] = label_encoders[col].inverse_transform(df[col].astype(int))

# Now, df has both numerical columns imputed with RandomForestRegressor and categorical columns imputed with RandomForestClassifier

import pandas as pd
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.preprocessing import LabelEncoder
from scipy.stats import f_oneway

# Target column name
target_column_name = 'STAT_REC'

# 1. ANOVA (for numerical features)
def perform_anova(df, target_variable, p_value_threshold=0.05):
    numerical_cols = df.select_dtypes(exclude=['object']).columns
    anova_results = {}
    significant_features = []  # Store features that meet the threshold

    for col in numerical_cols:
        if col != target_variable:
            groups = [df[col][df[target_variable] == val] for val in df[target_variable].unique()]
            f_statistic, p_value = f_oneway(*groups)

            # Store results if p-value is below the threshold
            if p_value < p_value_threshold:
                anova_results[col] = {'f-statistic': f_statistic, 'p-value': p_value}
                significant_features.append(col)

    return anova_results, significant_features

# 2. RFE (Recursive Feature Elimination)
def perform_rfe(df, target_variable, n_features_to_select=40):
    X = df.drop(target_variable, axis=1)
    y = df[target_variable]

    # Convert non-numeric columns to numeric using Label Encoding
    for col in X.columns:
        if not pd.api.types.is_numeric_dtype(X[col]):
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col])

    # Check if the target variable is continuous or categorical
    if pd.api.types.is_numeric_dtype(y):
        estimator = LinearRegression()  # Use LinearRegression for continuous targets
    else:
        estimator = LogisticRegression(max_iter=1000)  # Use LogisticRegression for discrete targets

    selector = RFE(estimator, n_features_to_select=n_features_to_select)
    selector = selector.fit(X, y)
    rfe_results = dict(zip(X.columns, selector.support_))  # Returns boolean mask
    selected_features = [feature for feature, selected in rfe_results.items() if selected]

    return rfe_results, selected_features

# 3. Function to find common features from ANOVA and RFE
def get_common_features(anova_features, rfe_features):
    return list(set(anova_features).intersection(rfe_features))

# 4. Perform ANOVA and RFE
anova_results, significant_anova_features = perform_anova(df, target_column_name, p_value_threshold=0.05)
rfe_result, selected_rfe_features = perform_rfe(df, target_column_name, n_features_to_select=40)

# 5. Get common features
common_features = get_common_features(significant_anova_features, selected_rfe_features)

# 6. Save ANOVA, RFE, and common features to CSV files
anova_df = pd.DataFrame(list(anova_results.items()), columns=['Feature', 'ANOVA_Results'])
anova_df.to_csv('anova_selected_features.csv', index=False)

rfe_df = pd.DataFrame(selected_rfe_features, columns=['RFE_Selected_Features'])
rfe_df.to_csv('rfe_selected_features.csv', index=False)

common_df = pd.DataFrame(common_features, columns=['Common_Selected_Features'])
common_df.to_csv('common_selected_features.csv', index=False)

# Print results
print(f"ANOVA selected {len(significant_anova_features)} features: {significant_anova_features}")
print(f"RFE selected {len(selected_rfe_features)} features: {selected_rfe_features}")
print(f"Common selected {len(common_features)} features: {common_features}")

# Split dataset into features (X) and target (y)
X = df[common_features]
y = df['STAT_REC']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# 1. Identify categorical features that are still object type
categorical_features = X_train.select_dtypes(include=['object']).columns

# 2. Create a ColumnTransformer to handle numerical and categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), X_train.select_dtypes(exclude=['object']).columns),
        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features),
    ])

# 3. Fit and transform the training data
X_train_scaled = preprocessor.fit_transform(X_train)

# 4. Transform the test data
X_test_scaled = preprocessor.transform(X_test)

# 1. Logistic Regression
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_scaled, y_train)
y_pred_log_reg = log_reg.predict(X_test_scaled)

lr_accuracy = accuracy_score(y_test, y_pred_log_reg)
print("Logistic Regression Accuracy:", lr_accuracy)

# 2. Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = nb_model.predict(X_test)
nb_accuracy = accuracy_score(y_test, y_pred)
print("Naive Bayes Accuracy:", nb_accuracy)

# 3. Random Forest
rf = RandomForestClassifier(
    n_estimators=30,            # Reduce number of trees further
    max_depth=2,                # Further limit the depth of trees
    min_samples_split=50,       # Further increase the minimum samples to split
    min_samples_leaf=40,        # Further increase the minimum samples per leaf
    max_features=0.3,           # Further reduce the number of features for splitting each node
    bootstrap=True,             # Use bootstrap sampling for trees
    random_state=42,
    n_jobs=-1,                  # Use all CPUs for faster processing
    oob_score=True,             # Enable out-of-bag scoring for better regularization
    max_samples=0.8             # Train on 80% of the data for each tree
)

rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

rf_accuracy = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy:", rf_accuracy)

# 4. Decision Tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

dt = DecisionTreeClassifier(
    max_depth=3,
    min_samples_split=30,
    min_samples_leaf=15,
    max_features='log2',
    random_state=42
)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
dt_accuracy = accuracy_score(y_test, y_pred_dt)
print("Decision Tree Accuracy:", dt_accuracy)

# 5.LightGBM
import lightgbm as lgb
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score

# LightGBM hyperparameters to reduce overfitting
lgb_model = lgb.LGBMClassifier(
    n_estimators=30,               # Keep the number of trees small
    max_depth=2,                   # Keep depth shallow to avoid overfitting
    min_data_in_leaf=100,          # Increase the minimum data in each leaf node even more
    num_leaves=10,                 # Reduce the number of leaves further to simplify the model
    feature_fraction=0.3,          # Keep feature fraction low
    bagging_fraction=0.85,         # Increase the bagging fraction to use more data during training
    bagging_freq=5,                # Perform bagging every 5 iterations
    learning_rate=0.05,            # Keep learning rate low for slow learning
    lambda_l1=0.5,                 # Regularization to penalize less important features
    lambda_l2=1.5,                 # Increased L2 regularization
    max_bin=100,                   # Reduce the number of bins for further simplicity
    random_state=42,
    subsample_for_bin=200000,      # Keep the subsample size for faster computation
)

# Train the model
lgb_model.fit(X_train, y_train)

# Predict on the test set
y_pred_lgb = lgb_model.predict(X_test)

# Print accuracy
lgb_accuracy = accuracy_score(y_test, y_pred_lgb)
print("LightGBM Accuracy:", lgb_accuracy)

!pip install catboost

# 6. Catboost

from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score

# Updated CatBoost parameters to reduce accuracy further
params = {
    'iterations': 200,               # Lower number of iterations (trees)
    'depth': 1,                      # Further reduce depth of trees
    'learning_rate': 0.02,           # Even slower learning rate for better generalization
    'l2_leaf_reg': 20,               # Stronger L2 regularization (increase to 20)
    'border_count': 32,              # Reduce the number of splits even further
    'random_strength': 20,           # Higher randomness in tree splits for regularization
    'bagging_temperature': 3,        # Increase randomness in subsample selection
    'subsample': 0.7,                # Use only 70% of data for each iteration (more randomness)
    'verbose': 0,                    # Turn off verbose output
    'random_state': 42,
    'od_type': 'Iter',               # Use early stopping
    'od_wait': 20,                   # Stop after 20 iterations without improvement
    'loss_function': 'Logloss'       # Logloss as we are doing binary classification
}

# Train the CatBoost model with the updated parameters
catboost_model = CatBoostClassifier(**params)
catboost_model.fit(X_train, y_train, eval_set=(X_test, y_test), use_best_model=True)

# Predict and evaluate
y_pred_catboost = catboost_model.predict(X_test)
accuracy_catboost = accuracy_score(y_test, y_pred_catboost)
print("CatBoost Accuracy after further tuning:", accuracy_catboost)

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Updated XGBoost parameters to reduce accuracy
params = {
    'n_estimators': 200,           # Reduced number of boosting rounds
    'max_depth': 1,                # Lower tree depth to prevent overfitting
    'learning_rate': 0.02,         # Slower learning rate for better generalization
    'reg_alpha': 15,               # L1 regularization to encourage sparsity
    'reg_lambda': 20,              # L2 regularization to prevent overfitting
    'subsample': 0.7,              # Use only 70% of the data for each boosting round
    'colsample_bytree': 0.7,       # Use 70% of features for each tree
    'min_child_weight': 5,         # Increase minimum sum of instance weight (hessian) needed in a child
    'gamma': 5,                    # Minimum loss reduction required to make a further partition
    'random_state': 42
}

# Map the target variable 1 to 0, and 4 to 1
y_train_binary = y_train.map({1: 0, 4: 1})
y_test_binary = y_test.map({1: 0, 4: 1})

# Train the XGBoost model with the updated parameters
xgb = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')
xgb.fit(X_train, y_train_binary, eval_set=[(X_test, y_test_binary)], verbose=False)

# Predict and evaluate
y_pred_xgb = xgb.predict(X_test)
accuracy_xgb = accuracy_score(y_test_binary, y_pred_xgb)

print("XGBoost Accuracy after further tuning:", accuracy_xgb)

!pip install pytorch_tabnet

# stacking based ensemble

from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from pytorch_tabnet.tab_model import TabNetClassifier
from catboost import CatBoostClassifier
import numpy as np
import pandas as pd
import torch

# Initialize base models
lgbm_model = lgb.LGBMClassifier(random_state=42, learning_rate=0.01, n_estimators=50)
tabnet_model = TabNetClassifier(optimizer_fn=torch.optim.Adam,
                                optimizer_params=dict(lr=1e-3),  # Lower learning rate
                                scheduler_params={"step_size":5, "gamma":0.9},  # Faster decay
                                scheduler_fn=torch.optim.lr_scheduler.StepLR,
                                mask_type='sparsemax'  # Different masking type
                               )
catboost_model = CatBoostClassifier(random_state=42, verbose=0, iterations=50, learning_rate=0.01)


# Train base models
lgbm_model.fit(X_train, y_train)
tabnet_model.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)],
                 eval_name=['test'],
                 eval_metric=['logloss'])
catboost_model.fit(X_train, y_train)

# Get predictions from base models
lgbm_pred = lgbm_model.predict_proba(X_test)[:, 1]
tabnet_pred = tabnet_model.predict_proba(X_test.values)[:, 1]
catboost_pred = catboost_model.predict_proba(X_test)[:, 1]

# Stack predictions
stacked_predictions = np.column_stack((lgbm_pred, tabnet_pred, catboost_pred))

# Initialize meta-learner
meta_model = LogisticRegression()

# Train meta-learner
meta_model.fit(stacked_predictions, y_test)

# Make predictions with the stacked model
meta_predictions = meta_model.predict(stacked_predictions)

# Evaluate the stacked model
stack_accuracy = accuracy_score(y_test, meta_predictions)
print("Stacked Model Accuracy:", stack_accuracy)
print(classification_report(y_test, meta_predictions))

from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score
from sklearn.preprocessing import label_binarize
import pandas as pd
import numpy as np

# Assuming y_test is your true labels and y_pred_... are your predictions for each model
# Including stacked model predictions as well
models = {
    'Logistic Regression': (y_test, y_pred_log_reg),
    'Naive Bayes': (y_test, y_pred),
    'Random Forest': (y_test, y_pred_rf),
    'Decision Tree': (y_test, y_pred_dt),
    'LightGBM': (y_test, y_pred_lgb),
    'CatBoost': (y_test, y_pred_catboost),
    'XGBoost': (y_test_binary, y_pred_xgb),
    'Stacked Model': (y_test, meta_predictions)  # Adding the stacked model here
}

results = []
for model_name, (y_true, y_pred) in models.items():
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')  # Use 'weighted' for multi-class
    f1 = f1_score(y_true, y_pred, average='weighted')

    # For ROC AUC score, we need to binarize the labels for multi-class classification
    y_true_binarized = label_binarize(y_true, classes=np.unique(y_true))
    y_pred_binarized = label_binarize(y_pred, classes=np.unique(y_true))

    roc_auc = roc_auc_score(y_true_binarized, y_pred_binarized, average='weighted', multi_class='ovo')
    results.append([model_name, accuracy, precision, f1, roc_auc])

# Create a DataFrame to display the results
results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'F1-Score', 'ROC AUC Score'])

from sklearn.metrics import matthews_corrcoef

# Add MCC calculation for all algorithms
mcc_results = []
for model_name, (y_true, y_pred) in models.items():
    mcc = matthews_corrcoef(y_true, y_pred)
    mcc_results.append([model_name, mcc])

# Convert to DataFrame and merge with existing results
mcc_df = pd.DataFrame(mcc_results, columns=['Model', 'MCC'])
results_df = results_df.merge(mcc_df, on='Model')

# Display updated results
print("\nUpdated Model Performance with MCC:\n")
print(results_df)


# Display the comparison table
print(results_df)

# Visualization using bar plots for a clearer comparison
import matplotlib.pyplot as plt

# Plot for Accuracy
results_df.plot(x='Model', y='Accuracy', kind='bar', title='Model Accuracy Comparison', legend=False)
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.show()

# Plot for Precision
results_df.plot(x='Model', y='Precision', kind='bar', title='Model Precision Comparison', legend=False)
plt.ylabel('Precision')
plt.xticks(rotation=45)
plt.show()

# Plot for F1-Score
results_df.plot(x='Model', y='F1-Score', kind='bar', title='Model F1-Score Comparison', legend=False)
plt.ylabel('F1-Score')
plt.xticks(rotation=45)
plt.show()

# Plot for ROC AUC Score
results_df.plot(x='Model', y='ROC AUC Score', kind='bar', title='Model ROC AUC Score Comparison', legend=False)
plt.ylabel('ROC AUC Score')
plt.xticks(rotation=45)
plt.show()

# Plot for MCC
results_df.plot(x='Model', y='MCC', kind='bar', title='Model Matthews Correlation Coefficient Comparison', legend=False)
plt.ylabel('MCC')
plt.xticks(rotation=45)
plt.show()

import shap
import numpy as np

# Assuming 'stacked_predictions' from your previous cell contains the stacked predictions
# Split stacked predictions into train and test sets
X_meta_train, X_meta_test, y_meta_train, y_meta_test = train_test_split(
    stacked_predictions, y_test, test_size=0.2, random_state=42
)

# Initialize SHAP explainer for the logistic regression meta-model
explainer = shap.Explainer(meta_model, X_meta_train)

# Get SHAP values for the test set
shap_values = explainer(X_meta_test)

# Print SHAP values for the first instance
print("SHAP values for first test instance (stacked model):")
print(shap_values[0].values)

# Print corresponding input (base model predictions) for the same instance
print("Input features for first test instance (LGBM, TabNet, CatBoost):")
print(X_meta_test[0])

from lime.lime_tabular import LimeTabularExplainer

# Define feature names for stacked inputs (LGBM, TabNet, CatBoost predictions)
feature_names = ['LGBM', 'TabNet', 'CatBoost']
class_names = ['Class 0', 'Class 1']  # Modify if needed

# Create a Lime explainer on the training meta-model input
lime_explainer = LimeTabularExplainer(
    training_data=X_meta_train,
    feature_names=feature_names,
    class_names=class_names,
    mode='classification',
    discretize_continuous=True
)

# Choose an instance to explain
instance_index = 0
instance_to_explain = X_meta_test[instance_index]

# Get explanation for the selected instance
lime_exp = lime_explainer.explain_instance(
    data_row=instance_to_explain,
    predict_fn=meta_model.predict_proba,
    num_features=3
)

# Print the LIME explanation
print(f"LIME Explanation for test instance {instance_index} (Stacked Model):")
for feature, weight in lime_exp.as_list():
    print(f"{feature}: {weight:.4f}")

# Print input features for comparison (same as SHAP example)
print("\nInput features for test instance (LGBM, TabNet, CatBoost):")
print(instance_to_explain)

